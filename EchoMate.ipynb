{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b50bbe2-c0b1-49c3-9a5c-1ba7efa2bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q ffmpeg\n",
    "\n",
    "!pip install -q openai-whisper\n",
    "\n",
    "!pip install -q torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58fd7314-2b94-4552-89aa-02027895a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import gradio as gr\n",
    "\n",
    "import os\n",
    "import json\n",
    "import whisper\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "from io import BytesIO\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "import ffmpeg \n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "747e8786-9da8-4342-b6c9-f5f69c2e22ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "    \n",
    "MODEL = \"gpt-4o-mini\"\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a521d84-d07c-49ab-a0df-d6451499ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an empathetic AI companion designed to help users improve their mood and reduce stress.\"\n",
    "system_message += \" Begin by asking the user about their current emotional state in a warm and non-intrusive manner.\"\n",
    "system_message += \" Ask one thoughtful and relevant question at a time based on the user's responses.\"\n",
    "system_message += \" Tailor your responses and suggestions based on the user's mood, emotional intensity and offer practical yet gentle recommendations, such as mindfulness techniques, or positive affirmations.\"\n",
    "system_message += \" Maintain a compassionate and understanding tone throughout the conversation.\"\n",
    "system_message += \" Conclude the session naturally when the user seems satisfied or ready to end the conversation.\"\n",
    "system_message += \" Summarize the key points discussed and provide words of encouragement before ending the session.\"\n",
    "system_message += \" Politely indicate the end of the session and remind the user that they can return anytime for more support.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bedabf-a0a7-4985-ad8e-07ed6a55a3a4",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0696acb1-0b05-4dc2-80d5-771be04f1fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mood_check_function = {\n",
    "    \"name\": \"mood_check\",\n",
    "    \"description\": \"Ask the user to reflect on their mood and emotions to better understand their current emotional state.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"current_mood\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"he user's current mood, such as 'calm', 'anxious', 'happy', 'frustrated', 'stressed', 'lonely' or 'excited'.\"\n",
    "            },\n",
    "            \"emotion_strength\": {\n",
    "                \"type\": \"string\",\n",
    "                \"enum\": [\"mild\", \"moderate\", \"strong\"],\n",
    "                \"description\": \"The intensity of the emotion being experienced.\"\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"current_mood\", \"emotion_strength\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4afceded-7178-4c05-8fa6-9f2085e6a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_assessment_function = {\n",
    "    \"name\": \"stress_level_assessment\",\n",
    "    \"description\": \"If the user is stressed then assess the user’s stress level based on their current feelings and external stressors.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"stress_cause\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"An explanation of the user’s current stressor, such as work, family, health.\"\n",
    "            },\n",
    "            \"stress_intensity\": {\n",
    "                \"type\": \"string\",\n",
    "                \"enum\": [\"low\", \"medium\", \"high\"],\n",
    "                \"description\": \"The intensity of the user’s perceived stress.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"stress_cause\", \"stress_intensity\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdca8679-935f-4e7f-97e6-e71a4d4f228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exercise_suggestion_function = {\n",
    "    \"name\": \"relaxation_exercise_suggestion\",\n",
    "    \"description\": \"Provide a personalized relaxation exercise based on the user's current mood and stress levels.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"mood_state\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The user’s current emotional state, such as 'stressed', 'calm', or 'anxious'.\"\n",
    "            },\n",
    "            \"stress_level\": {\n",
    "                \"type\": \"string\",\n",
    "                \"enum\": [\"low\", \"medium\", \"high\"],\n",
    "                \"description\": \"The level of stress the user is experiencing.\"\n",
    "            },\n",
    "            \"exercise_type\": {\n",
    "                \"type\": \"string\",\n",
    "                \"enum\": [\"breathing\", \"meditation\", \"physical\", \"visualization\"],\n",
    "                \"description\": \"The type of relaxation exercise to suggest.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"mood_state\", \"stress_level\", \"exercise_type\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8949898a-5fb4-452e-bc19-dac451a30b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_affirmation_function = {\n",
    "    \"name\": \"positive_affirmation\",\n",
    "    \"description\": \"Offer a positive affirmation to help the user shift their mindset and reduce negative thoughts.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"affirmation_type\": {\n",
    "                \"type\": \"string\",\n",
    "                \"enum\": [\"self-worth\", \"calmness\", \"strength\", \"hope\"],\n",
    "                \"description\": \"The type of affirmation to provide based on the user’s needs.\"\n",
    "            },\n",
    "            \"personalization_details\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Additional details about the user to personalize the affirmation (e.g., 'You are doing your best' or 'You are capable of handling challenges').\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"affirmation_type\", \"personalization_details\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2d5171f-2291-4f39-b04e-6f887f3ae78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reflection_function = {\n",
    "    \"name\": \"reflection_prompt\",\n",
    "    \"description\": \"Encourage the user to reflect on their day or experience to better understand their emotions and thoughts.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"reflection_type\": {\n",
    "                \"type\": \"string\",\n",
    "                \"enum\": [\"positive\", \"negative\", \"neutral\"],\n",
    "                \"description\": \"The type of reflection prompt to offer (e.g., focus on positive experiences, identify sources of negativity).\"\n",
    "            },\n",
    "            \"focus_area\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The area of focus for reflection, such as 'work', 'relationships', or 'personal growth'.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"reflection_type\", \"focus_area\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d926b41a-7c4e-468f-bb54-2911d6ca3919",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "concluding_function = {\n",
    "    \"name\": \"conclude_session\",\n",
    "    \"description\": \"Check if user wants to continue the mood and stress management session or conclude it with personlised insights.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"continue_session\": {\n",
    "                \"type\": \"boolean\",\n",
    "                \"description\": \"Indicates if the user wants to continue the session. If false, provide conclusion.\"\n",
    "            },\n",
    "            \"session_summary\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"A brief summary of the user's mood and emotions during the session, including key takeaways.\"\n",
    "            },\n",
    "            \"suggestions_for_improvement\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Suggestions to help the user improve their mood or reduce stress, personalized based on the user's emotional state.\"\n",
    "                },\n",
    "                \"description\": \"Personalized recommendations for improving mental well-being, such as exercises, activities, or self-care tips.\"\n",
    "            },\n",
    "            \"encouragement\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"A message of encouragement or affirmation to help the user feel supported and motivated moving forward.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"continue_session\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f18fd4cf-c774-4fd0-b5ed-833f29001a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\"type\": \"function\", \"function\": mood_check_function},\n",
    "    {\"type\": \"function\", \"function\": stress_assessment_function},\n",
    "    {\"type\": \"function\", \"function\": exercise_suggestion_function},\n",
    "    {\"type\": \"function\", \"function\": positive_affirmation_function},\n",
    "    {\"type\": \"function\", \"function\": reflection_function},\n",
    "    {\"type\": \"function\", \"function\": concluding_function},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d3554f-b4e3-4ce7-af6f-68faa6dd2340",
   "metadata": {},
   "source": [
    "## Getting OpenAI to the Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0992986-ea09-4912-a076-8e5603ee631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def handle_tool_call(message):\n",
    "    \"\"\"Handle tool calls based on the AI response.\"\"\"\n",
    "    tool_call = message.tool_calls[0]  # Assuming one tool call at a time\n",
    "    function_name = tool_call.function.name\n",
    "    arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "    response_content = {}\n",
    "\n",
    "    if function_name == \"mood_check_function\":\n",
    "        mood = arguments.get(\"current_mood\")\n",
    "        intensity = arguments.get(\"emotion_strength\")\n",
    "        response_content = {\"response\": f\"You are feeling {mood} with {intensity} intensity.\"}\n",
    "        \n",
    "    elif function_name == \"stress_assessment_function\":\n",
    "        stress_cause = arguments.get(\"stress_cause\")\n",
    "        stress_intensity = arguments.get(\"stress_intensity\")\n",
    "        response_content = {\"assessment\": f\"Your stress is caused by {stress_cause} with a {stress_intensity} intensity.\"}\n",
    "\n",
    "    elif function_name == \"exercise_suggestion_function\":\n",
    "        mood_state = arguments.get(\"mood_state\")\n",
    "        stress_level = arguments.get(\"stress_level\")\n",
    "        exercise_type = arguments.get(\"exercise_type\")\n",
    "        response_content = {\"suggestion\": f\"Since you're feeling {mood_state} with {stress_level} stress, try a {exercise_type} exercise.\"}\n",
    "\n",
    "    elif function_name == \"positive_affirmation_function\":\n",
    "        affirmation_type = arguments.get(\"affirmation_type\")\n",
    "        personalization_details = arguments.get(\"personalization_details\")\n",
    "        response_content = {\"affirmation\": f\"Here’s a {affirmation_type} affirmation for you: {personalization_details}\"}\n",
    "\n",
    "    elif function_name == \"reflection_function\":\n",
    "        reflection_type = arguments.get(\"reflection_type\")\n",
    "        focus_area = arguments.get(\"focus_area\")\n",
    "        response_content = {\"reflection\": f\"Let’s reflect on {focus_area} with a {reflection_type} approach.\"}\n",
    "    \n",
    "    elif function_name == \"concluding_function\":\n",
    "        continue_session = arguments.get(\"continue_session\")\n",
    "\n",
    "        if(continue_session):\n",
    "            response_content = {\"message\": \"Glad to hear you want to continue! Let me know what you are feeling and what you want to focus on next.\"}\n",
    "        else:\n",
    "            session_summary = arguments.get(\"session_summary\")\n",
    "            suggestions = arguments.get(\"suggestions_for_improvement\", [])\n",
    "            encouragement = arguments.get(\"encouragement\")\n",
    "            response_content = {\n",
    "                \"conclusion\": f\"Session Summary: {session_summary}. Suggestions: {', '.join(suggestions)}. Encouragement: {encouragement}\"}\n",
    "\n",
    "    response = {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps(response_content),\n",
    "        \"tool_call_id\": message.tool_calls[0].id\n",
    "    }\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4975b87-19e9-4ade-a232-9b809ec75c9a",
   "metadata": {},
   "source": [
    "## Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffbfe93b-5e86-4e68-ba71-b301cd5230db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "def talker(message):\n",
    "    response = openai.audio.speech.create(\n",
    "      model=\"tts-1\",\n",
    "      voice=\"onyx\",    \n",
    "      input=message\n",
    "    )\n",
    "    \n",
    "    audio_stream = BytesIO(response.content)\n",
    "    audio = AudioSegment.from_file(audio_stream, format=\"mp3\")\n",
    "    play(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5f8815a-2d8c-4944-aa24-d931726de097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "import whisper \n",
    "\n",
    "model  = whisper.load_model(\"tiny.en\")\n",
    "\n",
    "def transcribe(audio_file):\n",
    "    speech_to_text = model.transcribe(audio_file)[\"text\"]\n",
    "\n",
    "    return speech_to_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d48876d-c4fa-46a8-a04f-f9fadf61fb0d",
   "metadata": {},
   "source": [
    "# Agent Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d29714b6-b388-47bd-86d7-347ec563bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_audio(audio_file, history):\n",
    "    \"\"\"Handle user voice input, transcribe it, and provide an audio response.\"\"\"\n",
    "    if audio_file is not None:\n",
    "        try:\n",
    "            # Transcribe the audio\n",
    "            text = transcribe(audio_file)\n",
    "            \n",
    "            # Update history with user input\n",
    "            history.append({\"role\": \"user\", \"content\": text})\n",
    "            \n",
    "            # Generate AI response\n",
    "            response = openai.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=[{\"role\": \"system\", \"content\": system_message}] + history,\n",
    "                tools = tools\n",
    "            )\n",
    "\n",
    "            if response.choices[0].finish_reason==\"tool_calls\":\n",
    "                message = response.choices[0].message\n",
    "                response = handle_tool_call(message)\n",
    "                messages.append(message)\n",
    "                messages.append(response)\n",
    "                response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "            \n",
    "            # Access the AI response message content\n",
    "            reply = response.choices[0].message.content\n",
    "            \n",
    "            # Update history with AI response\n",
    "            history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "            \n",
    "            # Respond using text-to-speech\n",
    "            talker(reply)\n",
    "            \n",
    "            return history  # Return updated chatbot display\n",
    "        finally:\n",
    "            if os.path.exists(audio_file):\n",
    "                os.remove(audio_file)  # Clean up temporary file\n",
    "\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e03cb5c9-e8ef-4bea-846e-659b626f6452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500, type=\"messages\", label=\"AI Assistant\")  # Chatbot to display conversation\n",
    "\n",
    "    with gr.Row():\n",
    "        audio_input = gr.Audio(type=\"filepath\", label=\"Speak to AI\")  # Audio input for user voice\n",
    "\n",
    "    with gr.Row():\n",
    "        clear = gr.Button(\"Clear\")\n",
    "\n",
    "    # Audio input handling\n",
    "    audio_input.stop_recording(\n",
    "        handle_audio, \n",
    "        inputs=[audio_input, chatbot], \n",
    "        outputs=chatbot\n",
    "    ).then(\n",
    "        lambda history: history, \n",
    "        inputs=[chatbot], \n",
    "        outputs=chatbot\n",
    "    )\n",
    "\n",
    "    # Clear button to reset history\n",
    "    clear.click(lambda: ([{\"role\": \"system\", \"content\": system_message}], [{\"role\": \"system\", \"content\": system_message}]), \n",
    "                inputs=None, outputs=chatbot, queue=False)\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e39e42-13d2-4271-b8b3-3a14b8a12bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
